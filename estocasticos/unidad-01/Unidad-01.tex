% =================================================================
\documentclass[ 10pt, xcolor = dvipsnames]{beamer}
\usepackage{ beamerthemesplit, lmodern}
\usetheme{Madrid}
\usecolortheme[named=Brown]{structure}
\useinnertheme{rectangles}
\setbeamertemplate{frametitle continuation}{}
\beamertemplatenavigationsymbolsempty
\usepackage{../../macros-general}
\usepackage{../../macros-beamer}
\input{../../beamer_section-slides}

% =================================================================
\newcommand{\shorttitle}{Modelos Estoc\'asticos - Unidad 01}
\title[\shorttitle]{Modelos Estoc\'asticos para Manufactura y Servicios (INDG-1008): \textbf{Unidad 01} }
\author[L. I. Reyes Castro]{Luis I. Reyes Castro}
\institute[ESPOL]{\normalsize Escuela Superior Polit\'ecnica del Litoral (ESPOL) \\ Guayaquil - Ecuador}
\date[2017-T1]{2017 - Primer T\'ermino}

% -----------------------------------------------------------------
\begin{document}
\input{../../beamer_table-contents}
\input{../../macros-espanol}

% =================================================================
\section{Repaso de Variables Aleatorias}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Valor Esperado:}
\begin{itemize}
\item Si $X$ es una variable aleatoria discreta entonces 
\[
\Exp[X] \, = \, \sum_{ x \, \in \, \support(X) } x \, \Pr(x)
\]
donde la sumatoria es sobre todos los valores que puede tomar $X$. 
\item Si $X$ es una variable aleatoria continua entonces 
\[
\Exp[X] \, = \, \int_{ x \, \in \, \support(X) } x \, f(x) \, dx
\]
donde la integraci\'on es sobre todos los valores que puede tomar $X$. 
\item Si $X,Y$ son variables aleatorias y $a,b$ son constantes entonces: 
\[
\Exp[ \, a X + b Y \, ] \, = \, a \, \Exp[X] + b \, \Exp[Y]
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Independecia de Variables Aleatorias:}
\begin{itemize}
\item Decimos que las variables aleatorias discretas $X,Y$ son independientes si \linebreak para todo posible par de valores $(x,y)$ que las variables aleatorias \linebreak pueden tomar es el caso que: 
\[
\Pr( \, X = x, \, Y = y \, ) \, = \,
\Pr( \, X = x \, ) \, \Pr( \, Y = y \, )
\]
\item Si $X,Y$ son variables aleatorias independientes entonces: 
\[
\Exp[XY] \, = \, \Exp[X] \, \Exp[Y]
\]
N\'otese que esta relaci\'on en general no es v\'alida par variables aleatorias dependientes. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\begin{itemize}
\item Si $X,Y$ son dos variables aleatorias entonces la probabilidad del valor $x$ de la primera variable condicional en el valor $y$ de la segunda esta dado por: 
\[
\Pr( \, X = x \mid Y = y \, ) \, = \, 
\frac{ \Pr( \, X = x, \, Y = y ) }{ \Pr( \, Y = y \, ) }
\]
\item Claramente, si $X,Y$ son variables aleatorias independientes entonces para todo valor $x$ de la primera variable y todo valor $y$ de la segunda: 
\[
\Pr( \, X = x \mid Y = y \, ) \, = \, \Pr( \, X = x \, )
\]
\framebreak
\item Si $X,Y$ son dos variables aleatorias entonces para todo valor $y$ de la \linebreak segunda variable aleatoria: 
\[
\Exp[ \, X \mid Y  = y \, ] \, = \, \sum_{ x \, \in \, \support( X \mid Y = y ) } x \, \Pr( \, X = x \mid \, Y = y )
\]
\item Si $X,Y$ son dos variables aleatorias entonces: 
\[
\Exp[X] \, = \, \Exp[ \, \Exp[ \, X \mid Y \, ] \, ] \, = \, 
\sum_{ y \, \in \, \support(Y) } \Exp[ \, X \mid Y = y \, ] \,
\Pr( \, Y = y \, )
\]

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Bernoulli:}
\begin{itemize}
\item La variable aleatoria $\Bernoulli(p)$ representa la ocurrencia o no ocurrencia \linebreak de alg\'un evento de inter\'es que sucede con probabilidad $p$, \eg el resultado de lanzar una moneda sesgada. 
\item Si $X \sim \Bernoulli(p)$ entonces su distribucion es: 
\[
\Pr( \, X = 0 \, ) \, = 1 - p \qquad \qquad \qquad
\Pr( \, X = 0 \, ) \, = p
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, p \qquad \qquad \qquad
\var(X) \, = \, p \, (1-p)
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Binomial:}
\begin{itemize}
\item La variable aleatoria $\Binomial(n,p)$ representa el n\'umero de ensayos exitosos en un experimento que involucra $n$ ensayos independientes donde uno de los cuales tiene \'exito con probabilidad $p$. 
\item Alternativamente, puede ser reconocida como la suma de variables aleatorias Bernoulli independientes e id\'enticamente distrib\'idas. \Ie si $X_1, \dots, X_n$ son variables i.i.d. con distribuci\'on $\Bernoulli(p)$ entonces: 
\[
Z = X_1 + \cdots + X_n \qquad \Longrightarrow \qquad
Z \sim \Binomial(n,p)
\]
\framebreak
\item Si $Z \sim \Binomial(n,p)$ entonces su distribucion es: 
\[
\forall \, k \in \{ \, 0, \, 1, \, \dots, \, n \} \; \colon \;
\Pr( \, Z = k \, ) \; = \; {n \choose k} p^k \, (1-p)^k
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, n \, p \qquad \qquad \qquad
\var(X) \, = \, n \, p \, (1-p)
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Geom\'etrica:}
\begin{itemize}
\item Tenemos dos tipos. Yo las denoto aqu\'i como $\Geo(p)_0$ y $\Geo(p)_1$ pero son realmente la misma variable aleatoria pues: 
\[
\Geo(p)_0 + 1 \; \sim \; \Geo(p)_1
\]

\item Para interpretarlas consideraremos una secuencia de experimentos independientes, donde cada uno tiene \'exito con probabilidad $p$, \linebreak que concluye con el primer experimento exitoso. 
\framebreak

\item La variable aleatoria $\Geo(p)_0$ representa el n\'umero de experimentos fallidos que transcurrieron antes del primer experimento exitoso. 
\begin{itemize}
\item Si $X \sim \Geo(p)_0$ entonces su distribucion es: 
\[
\forall \, k \geq 0 \; \colon \;
\Pr( \, X = k \, ) \; = \; (1-p)^k \, p
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \frac{1-p}{p} \qquad \qquad \qquad
\var(X) \, = \, \frac{1-p}{p^2}
\]
\end{itemize}
\framebreak

\item La variable aleatoria $\Geo(p)_1$ representa la longitud de la secuencia de experimentos, \ie el n\'umero de experimentos realizados. 
\begin{itemize}
\item Si $X \sim \Geo(p)_1$ entonces su distribucion es: 
\[
\forall \, k \geq 1 \; \colon \;
\Pr( \, X = k \, ) \; = \; (1-p)^{k-1} \, p
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \frac{1}{p} \qquad \qquad \qquad
\var(X) \, = \, \frac{1-p}{p^2}
\]
\end{itemize}

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Exponencial:}
\begin{itemize}
\item La variable aleatoria $\Exponential(\lambda)$ es com\'unmente utilizada para modelar los tiempos entre arribos o eventos de inter\'es en un proceso estoc\'astico en tiempo continuo. 
\item Si $X \sim \Exponential(\lambda)$ entonces su distribucion es: 
\[
\forall \, t \geq 0 \; \colon \;
f_X(t) \; = \; \lambda \, e^{ -\lambda t}
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \frac{1}{\lambda} \qquad \qquad \qquad
\var(X) \, = \, \frac{1}{\lambda^2}
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Problema - H\&L 17.4-3:}

El tiempo que requiere un mec\'anico para reparar una m\'aquina tiene una distribuci\'on exponencial con media de 4 horas. Sin embargo, una herramienta especial reducir\'ia esta media a 2 horas. Si el mec\'anico repara una m\'aquina en menos de 2 horas, se le pagan
\$100; de otra manera se le pagan \$80. Determine el aumento esperado en el pago del mec\'anico si usa esta herramienta especial. 

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Resoluci\'on:}
\begin{itemize}
\item Si denotamos a $X$ como el tiempo que demora el mec\'anico en arreglar una m\'aquina actualmente entonces: 
\[
X \sim \Exponential( \lambda = 0.25 )
\]
\item Pago del mec\'anico actualmente:
\begin{itemize}
\item Si $0 \leq X \leq 2$ gana \$100, lo cual sucede con probabilidad: 
\[
\int_{t=0}^2 \lambda \, e^{ -\lambda \, t } dt \; = \;
\int_{t=0}^2 0.25 \, e^{ -0.25 \, t } dt \; = \; 0.393469
\]
\item Si $X > 2$ gana \$80, lo cual sucede con probabilidad:
\[
1 - 0.393469 = 0.606531
\]
\framebreak
\item Consecuentemente el pago esperado es: 
\[
\$100 \, (0.393469) + \$80 \, (0.606531) \, = \, \$87.87
\]
\end{itemize}
\item Luego, con la nueva m\'aquina tenemos que: 
\[
X \sim \Exponential( \lambda = 0.5 )
\]
\item Pago del mec\'anico con la nueva  m\'aquina: 
\begin{itemize}
\item Si $0 \leq X \leq 2$ gana \$100, lo cual sucede con probabilidad: 
\[
\int_{t=0}^2 \lambda \, e^{ -\lambda \, t } dt \; = \;
\int_{t=0}^2 0.50 \, e^{ -0.50 \, t } dt \; = \; 0.632121
\]
\framebreak
\item Si $X > 2$ gana \$80, lo cual sucede con probabilidad:
\[
1 - 0.632121 = 0.367879
\]
\item Consecuentemente el pago esperado es: 
\[
\$100 \, (0.632121) + \$80 \, (0.367879) \, = \, \$92.64
\]
\end{itemize}
\item Finalmente, el aumente en el pago del mec\'anico gracias a que usa la nueva m\'aquina es de \$4.67. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Poisson:}
\begin{itemize}
\item La variable aleatoria $\Poisson(\mu)$ es com\'unmente utilizada para modelar el n\'umero de arribos o eventos de inter\'es en un proceso estoc\'astico a lo largo de un intervalo de tiempo. 
\item Si $X \sim \Poisson(\mu)$ entonces su distribucion es: 
\[
\forall \, k \geq 0 \; \colon \;
\Pr( \, X = k \, ) \; = \; \frac{\mu^k \, e^{-\mu} }{k!}
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \mu \qquad \qquad \qquad
\var(X) \, = \, \mu
\]
\end{itemize}

\end{frame}

% =================================================================
\section{Proceso Bernoulli}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Ejemplo aleatorio:}

En una f\'abrica una m\'aquina tiene un componente que usualmente debe ser reemplazado. A pesar de que reemplazar el componente toma unos pocos minutos al final de la jornada de trabajo, cada d\'ia de operaci\'on de la m\'aquina el componente se puede da\~nar con probabilidad $p$, independientemente de lo que haya pasado antes. Con esto en mente: 
\begin{itemize}
\item Cu\'antas veces a la semana, en promedio, tendr\'an que reemplazar el componente? 
\item Si han pasado cuatro d\'ias desde la \'ultima vez que se cambi\'o en componente, cu\'al es la probabilidad de que se da\~ne ma\~nana? 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Proceso Bernoulli con par\'ametro $p$:}
\begin{itemize}
\item Es una secuencia de variables aleatorias Bernoulli con par\'ametro $p$ independientes e ind\'enticamente distribuidas que representan la \linebreak presencia o ausencia de arribos. 
\item Formalmente es una secuencia de variables aleatorias $X_1, \, X_2, \, X_3, \, X_4, \, \dots$ donde: 
\begin{itemize}
\item Para todo \'indice $i$ tenemos que $X_i \sim \Bernoulli(p)$. 
\item Para todo par de \'indices $i,j$ es el caso que $X_i$ es independiente de $X_j$. 
\end{itemize}
\item Consideramos que ocurre un arribo en el per\'iodo $t$ si $X_t = 1$; caso contrario no ocurri\'o un arribo en ese per\'iodo. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Tiempo entre arribos:}
\begin{itemize}
\item Para todo \'indice $i$ la variable aleatoria $T_i$ representa el n\'umero de per\'iodos que transcurrieron desde el $i$\tsup{avo} arribo hasta el $(i+1)$\tsup{avo} arribo. 
\begin{itemize}
\item N\'otese que $\support(T_i) = \ZNN$. 
\end{itemize}
\item Cu\'al es la distribuci\'on de $T_1$? \Ie para cada valor $k \in \ZNN$, cu\'al es la \linebreak probabilidad de que $T_1 = k$? 
\begin{itemize}
\item Claramente $k = 0$ con probabilidad $p$. 
\item Si $k = 1$ entonces $X_1 = 0$ y $X_2 = 1$, \ie en el primer per\'iodo no hubo un arribo y en el segundo per\'iodo hubo un arribo, lo cual sucede con \linebreak probabilidad $(1-p) \, p$. 
\item Si $k = 2$ entonces $X_1 = 0$, $X_2 = 0$ y $X_3 = 1$, lo cual sucede con \linebreak probabilidad $(1-p)^2 \, p$. 
\end{itemize}
\framebreak
\item Continuando por inducci\'on matem\'atica, vemos que: 
\[
\forall \, k \in \ZNN \; \colon \; 
\Pr( \, T_1 = k \, ) \, = \, (1-p)^k \, p 
\quad \Longleftrightarrow \quad T_1 \sim \Geo(p)_0
\]
\item \underline{Teorema:} Para cada \'indice $i$ es el caso que $T_i \sim \Geo(p)_0$. 
\item \underline{Corolario:} En un proceso Bernoulli con par\'ametro $p$ los tiempos entre arribos constituyen una secuencia de variables aleatorias independientes e identicamente distribuidas; en particular, con distribuci\'on $\sim \Geo(p)_0$. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{N\'umero de arribos en un intervalo:}
\begin{itemize}
\item Si para todo \'indice $k$ denotamos a la variable aleatoria $N_k$ como el n\'umero \linebreak de arribos desde el comienzo del proceso hasta el $k$\tsup{avo} periodo, entonces: 
\[
N_k \, = \, \sum_{t=1}^k X_t
\]
\item \Ie la variable aleatoria $N_k$ es la suma de $k$ variables aleatorias Bernoulli con par\'ametro $p$ independientes e identicamente distribuidas (IID). 
\item \underline{Teorema:} Para cada \'indice $k$ es el caso que $N_k \sim \Binomial(k,p)$. 
\item \underline{Corolario:} En un proceso Bernoulli con par\'ametro $p$ el n\'umero de arribos \linebreak a lo largo de un intervalo de $k$ per\'iodos es una variable aleatoria con distribuci\'on binomial con par\'ametros $k$ y $p$. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Combinaci\'on de Procesos Bernoulli:}
\begin{itemize}
\item Supongamos que tenemos dos procesos Bernoulli independientes. 
\begin{itemize}
\item El primero tiene par\'ametro $p$. 
\item El segundo tiene par\'ametro $q$. 
\end{itemize}
\item Consideremos un nuevo proceso donde se produce un arribo si y solo si \linebreak ocurre un arribo en ambos procesos. 
\begin{itemize}
\item Los arribos en el nuevo proceso son independientes entre si, pues en cada per\'iodo solo dependen en los arribos de los procesos generadores, los cuales \linebreak no dependen de arribos en tiempos anteriores. 
\item La probabilidad de un arribo en el nuevo proceso es el producto de las probabilidades de arribo en cada proceso generador, pues los procesos generadores son independientes. 
\item En conclusi\'on el nuevo proceso es un proceso Bernoulli con par\'ametro $pq$. 
\end{itemize}
\framebreak
\item Consideremos un nuevo proceso donde se produce un arribo si y solo si \linebreak ocurre un arribo en alguno de los dos procesos. 
\begin{itemize}
\item Los arribos en el nuevo proceso son independientes entre si, pues en cada per\'iodo solo dependen en los arribos de los procesos generadores, los cuales \linebreak no dependen de arribos en tiempos anteriores. 
\item La probabilidad de un arribo en el nuevo proceso es uno menos la probabilidad de que no haya un arribo, la cual es el producto de las probabilidades de que no hayan arribos en cada uno de los procesos generadores, pues los procesos generadores son independientes. 
\item En conclusi\'on el nuevo proceso es un proceso Bernoulli con par\'ametro $1 - (1-p)(1-q)$. 
\end{itemize}

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Divisi\'on de Procesos Bernoulli:}
\begin{itemize}
\item Supongamos que tenemos un proceso Bernoulli con par\'ametro $p$ que genera dos procesos. 
\item En cada per\'iodo: 
\begin{itemize}
\item Si el proceso principal produce un arribo, lanzamos una moneda sesgada con probabilidad de cara igual a $q$. 
\item Si la moneda sale cara enviamos el arribo al primer proceso. 
\item Si la moneda sale sello enviamos el arribo al segundo proceso. 
\end{itemize}
\item Entonces: 
\begin{itemize}
\item El primer proceso ser\'a un proceso Bernoulli con par\'ametro $p \, q$. 
\item El segundo proceso ser\'a un proceso Bernoulli con par\'ametro $p \, (1-q)$. 
\end{itemize}
\end{itemize}

\end{frame}

% =================================================================
\section{Proceso Poisson}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Proceso Poisson con par\'ametro $\lambda$:}
\begin{itemize}
\item Es una secuencia de variables aleatorias exponenciales con par\'ametro $\lambda$ independientes e ind\'enticamente distribuidas que representan los tiempos entre arribos. 
\item Formalmente es una secuencia de variables aleatorias $X_1, \, X_2, \, X_3, \, X_4, \, \dots$ donde: 
\begin{itemize}
\item Para todo \'indice $i$ tenemos que $X_i \sim \Exponential(\lambda)$. 
\item Para todo par de \'indices $i,j$ es el caso que $X_i$ es independiente de $X_j$. 
\end{itemize}
\item El proceso empieza en el tiempo cero, \ie $t = 0$, el primer arribo ocurre en \linebreak el tiempo $t = X_1$, el segundo en el tiempo $t = X_1 + X_2$, y as\'i sucesivamente; \ie el $i$\tsup{avo} arribo ocurre en: 
\[
t \, = \, X_1 + \cdots + X_i
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Propiedades estad\'isticas:}
\begin{itemize}
\item \underline{Falta de memoria:} \\ En cada instante del proceso, la distribuci\'on del tiempo que falta para el siguiente arribo es independiente del tiempo transcurrido desde el \linebreak \'ultimo arribo. M\'as formalmente, para todo \'indice de arribo $i$: 
\[
\forall \; t, \, \tau > 0 \; \colon \;
\Pr( \, X_i > t + \tau \mid X_i > t \, ) \; = \;
\Pr( \, X_i > \tau \, )
\]
\item \underline{N\'umero de arribos en un intervalo:} \\ En un proceso Poisson con par\'ametro $\lambda$ el n\'umero de arribos en un intervalo de $\tau$ unidades es una variable aleatoria Poisson con par\'ametro $\lambda \, \tau$. 
\item \underline{Arribos en intervalos disjuntos:} \\ Si dos intervalos de tiempo son disjuntos entonces el n\'umero de arribos durante esos intervalos son estad\'isticamente independientes. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Combinaci\'on de Procesos Poisson:}
\begin{itemize}
\item Supongamos que tenemos dos procesos independientes. 
\begin{itemize}
\item El primero es un proceso Poisson con par\'ametro $\lambda_1$.
\item El segundo es un proceso Poisson con par\'ametro $\lambda_2$.
\end{itemize}
\item Entonces, si consideremos un nuevo proceso que combina los arribos de \linebreak los dos procesos anteriores, el nuevo proceso es de hecho un \linebreak proceso Poisson con par\'ametro:
\[
\lambda_1 + \lambda_2
\]
\item Lo mismo aplica para la combinaci\'on de cualquier n\'umero de procesos independientes siempre y cuando cada uno sea un proceso Poisson. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Divisi\'on de Procesos Poisson:}
\begin{itemize}
\item Supongamos que tenemos un proceso Poisson con par\'ametro $\lambda$ que genera dos procesos de tal manera que en cada instante: 
\begin{itemize}
\item Si el proceso principal produce un arribo, lanzamos una moneda sesgada con probabilidad de cara igual a $p$. 
\item Si la moneda sale cara enviamos el arribo al primer proceso. 
\item Si la moneda sale sello enviamos el arribo al segundo proceso. 
\end{itemize}
\item Entonces: 
\begin{itemize}
\item El primer proceso ser\'a un proceso Poisson con par\'ametro $\lambda \, p$. 
\item El segundo proceso ser\'a un proceso Poisson con par\'ametro $\lambda \, (1-p)$. 
\end{itemize}
\end{itemize}

\end{frame}

% =================================================================
\section{Cadenas de Markov}

% =================================================================
\subsection{Modelamiento}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Una \textbf{Cadena de Markov} es un modelo matem\'atico de un proceso estoc\'astico \linebreak en tiempo discreto constitu\'ido por: 
\begin{itemize}
\item Conjunto finito de $n$ estados, donde cada estado es una representaci\'on de una posible situaci\'on de inter\'es. 
\item Matriz de transici\'on $\vec{P} \in \Re^{n \times n}$, donde: 
\begin{itemize}
\item Para cada par de estados $i,j$: 
\[
\vec{P}(i,j) \, = \, 
\Pr \, ( \, 
\text{siguiente estado sea } j \mid
\text{estado actual es } i \, )
\]
\item Cada una de las filas de la matriz suman a uno. 
\end{itemize}
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\textbf{H\&L, Secci\'on 16.1 - Ejemplo de Clima:}

El clima en el pueblo de Centerville puede cambiar con rapidez de un d\'ia a otro. Sin embargo, las posibilidades de tener clima seco (sin lluvia) ma\~nana es de alguna forma mayor si hoy est\'a seco, es decir, si no llueve. En particular, \linebreak la probabilidad de que ma\~nana este seco es de 0.8 si hoy est\'a seco, pero \linebreak es de solo 0.6 si hoy llueve. Estas probabilidades no cambian si se considera \linebreak la informaci\'on acerca del clima en los d\'ias anteriores a hoy. 

Modele este proceso clim\'atico como una Cadena de Markov. 
\framebreak

Estados: 
\begin{enumerate}
\item Est\'a seco
\item Llueve
\end{enumerate}

Matriz de transici\'on:
\[
\vec{P} \, = \, 
\left[
\begin{array}{cc}
0.8 & 0.2 \\ 0.6 & 0.4
\end{array}
\right]
\]

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\textbf{H\&L, Secci\'on 16.1 - Ejemplo en Manejo de Inventario:}

La tienda de fotograf\'ia de Dave se admministra semanalmente y est\'a abierta al p\'ublico desde el lunes en la ma\~nana hasta el s\'abado en la noche. Dave tiene en almac\'en un modelo especial de c\'amara que se vende relativamente bien. \linebreak Sean $D_1, \, D_2, \, D_3, \dots$ las demandas semanales de la c\'amara en unidades, \linebreak \ie el n\'umero de unidades que se vender\'ian si el inventario fuere inagotable. \linebreak M\'as precisamente, suponga que las demandas $D_t$ son variables aleatorias i.i.d. \linebreak que siguen una distribuci\'on Poisson con par\'ametro $\lambda = 1$. 

Dave maneja el inventario de acuerdo a la siguiente pol\'itica:
\begin{itemize}
\item Si no hay unidades de la c\'amara en inventario, se hace un pedido al proveedor por tres unidades. En este caso, el proveedor entregar\'a el pedido \linebreak el lunes a primera hora, justo antes de que la tienda abra. 
\item Caso contrario, no se hace un pedido. 
\end{itemize}
\framebreak

Definiendo a los cuatro posibles n\'umero de c\'amaras en inventario al final de cada semana como los estados, modele la pol\'itica de inventario descrita como una Cadena de Markov. 

Por si acaso, el orden de las actividades de la \tava semana es: 
\begin{enumerate}
\item Si se hizo un pedido al proveedor de las c\'amaras al final de la \linebreak \tmava semana se reciben las unidades que se pidieron. 
\item Se abre la tienda desde el lunes en la ma\~nana hasta el s\'abado en la noche. Durante este tiempo se venden entre cero y tres c\'amaras. 
\item Se cierra la tienda. 
\item De ser necesario, se hace un pedido al proveedor de las c\'amaras. 
\end{enumerate}
\framebreak

Estados: 
\begin{enumerate}
\item Quedan 0 unidades en inventario al final de la semana
\item Quedan 1 unidades en inventario al final de la semana
\item Quedan 2 unidades en inventario al final de la semana
\item Quedan 3 unidades en inventario al final de la semana
\end{enumerate}

Matriz de transici\'on:
\[
\vec{P} \, = \, 
\left[
\begin{array}{cccc}
0.08 & 0.18 & 0.37 & 0.37 \\
0.63 & 0.37 & 0    & 0    \\
0.26 & 0.37 & 0.37 & 0    \\
0.08 & 0.18 & 0.37 & 0.37
\end{array}
\right]
\]

\framebreak

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Definici\'on Formal: 
\begin{itemize}
\item Es una secuencia de variables aleatorias discretas $X_0, \, X_1, \, X_2, \, X_3, \, \dots$ \linebreak donde para cada \'indice de tiempo discreto $t$ la variable aleatoria $X_t$ \linebreak es el estado del proceso en el tiempo $t$. 
\item Tiene la \textbf{Propiedad Markoviana}, \ie que para cualquier historia de estados que culmina en el estado actual $x_0, \, x_1, \, \dots, \, x_t$ y para cualquier posible \linebreak estado futuro $x_{t+1}$ es el caso que: 
\begin{align*}
& \Pr( \, X_{t+1} = x_{t+1} \mid 
X_{0} = x_{0}, \, X_{1} = x_{1}, \, \dots, \, x_{t} = x_{t} \, ) \\[1ex]
& = \, \Pr( \, X_{t+1} = x_{t+1} \mid X_{t} = x_{t} \, )
\end{align*}
\fullcut
\halfcut
\begin{itemize}
\item Observe adem\'as que por definici\'on de la matriz de transici\'on $\vec{P}$ : 
\[
\vec{P}(i,j) \, = \,
\Pr( \, X_{t+1} = j \mid X_{t} = i \, )
\]
\end{itemize}

\end{itemize}

\end{frame}

% =================================================================
\subsection{Distribuci\'on en Estado Estable}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Propagaci\'on de la Distribuci\'on Inicial: 
\begin{itemize}
\item Supongamos que el estado inicial de una Cadena de Markov no es conocido \linebreak a priori sino que obedece una distribuci\'on inicial $\vec{\pi_0} \in \Re^n$, donde: 
\[
\forall x \colon \, \vec{\pi_0}(x) \, = \, \Pr( \, X_0 = x \, )
\]
\item Como caso especial, sup\'ongase que el estado inicial es conocido, \eg \linebreak que $X_0 = x_0$. Entonces la distribuci\'on inicial ser\'ia: 
\[
\vec{\pi_0}(x_0) \, = \, 1; \qquad
\forall x \neq x_0 \colon \, \vec{\pi_0}(x) \, = \, 0;
\]
\end{itemize}
\framebreak

\begin{itemize}
\item Ahora, si denotamos a $\vec{\pi_1}$ como la distribuci\'on del primer estado, \linebreak tenemos que para todo posible primer estado $x_1$ :
\begin{align*}
\forall x_1 \colon \, \vec{\pi_1}(x_1) \, 
& = \, \Pr( \, X_1 = x_1 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_0} \Pr( \, X_0 = x_0 \, ) \; \Pr( \, X_1 = x_1 \mid X_0 = x_0 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_0} \vec{\pi_0}(x_0) \, \vec{P}(x_0,x_1)
\end{align*}
\item Matricialmente, eso equivale a: 
\[
\vec{\pi_1'} \, = \, \vec{\pi_0'} \, \vec{P}
\]
\end{itemize}
\framebreak

\begin{itemize}
\item Luego, si denotamos a $\vec{\pi_2}$ como la distribuci\'on del segundo estado, \linebreak tenemos que para todo posible segundo estado $x_2$ :
\begin{align*}
\forall x_2 \colon \, \vec{\pi_2}(x_2) \,
& = \, \Pr( \, X_2 = x_2 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_1} \Pr( \, X_1 = x_1 \, ) \; \Pr( \, X_2 = x_2 \mid X_1 = x_1 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_1} \vec{\pi_1}(x_1) \, \vec{P}(x_1,x_2)
\end{align*}
\item Matricialmente, tenemos que: 
\[
\vec{\pi_2'} \, = \, \vec{\pi_1'} \, \vec{P}
\]
\end{itemize}
\framebreak

\begin{itemize}
\item M\'as generalmente, si conocemos la distribuci\'on del estado actual $\vec{\pi_t}$, entonces para la distribuci\'on del siguiente estado, denotada $\vec{\pi_{t+1}}$, \linebreak es el caso que: 
\begin{align*}
\forall x_{t+1} \colon \, \vec{\pi_{t+1}}(x_{t+1}) \, 
& = \, \Pr( \, X_{t+1} = x_{t+1} \, ) \\[1ex]
& = \, \sum_{\text{estados } x_t} \Pr( \, X_t = x_t \, ) \; \Pr( \, X_{t+1} = x_{t+1} \mid X_t = x_t \, ) \\[1ex]
& = \, \sum_{\text{estados } x_t} \vec{\pi_t}(x_t) \, \vec{P}(x_t,x_{t+1})
\end{align*}
\item Matricialmente, tenemos que: 
\[
\vec{\pi_{t+1}'} \, = \, \vec{\pi_t'} \, \vec{P}
\]
\end{itemize}
\framebreak

\begin{itemize}
\item Usando inducci\'on matem\'atica, es f\'acil ver que: 
\[
\forall t \geq 1 \colon \;
\vec{\pi_t'} \, = \, \vec{\pi_0'} \, \vec{P}^t
\]
\item Adem\'as, si la Cadena de Markov no tiene ciclos determin\'isicos entonces \linebreak sin importar la distribuci\'on inicial $\vec{\pi_0}$ es el caso que la distribuci\'on del \linebreak estado actual $\vec{\pi_t}$ converge a una \'unica distribuci\'on $\vec{\pi^*}$, conocida como la distribuci\'on en estado estable o estacionaria de la cadena. \Iec 
\[
\exists! \, \vec{\pi^*} \in \Re^n \colon \;
\lim_{ t \rightarrow \infty } \vec{\pi_t} \; = \;
\vec{\pi^*}
\]
\end{itemize}
\framebreak

\begin{itemize}
\item Finalmente, si la distribuci\'on en estado estable (estacionaria) existe \linebreak entonces dicha distribuci\'on es invariante: 
\[
\vec{(\pi^*)'} \, = \, \vec{(\pi^*)'} \, \vec{P}
\]
\item Esto implica que si la distribuci\'on del estado inicial es igual a la distribuci\'on estacionaria, \ie que si $X_0 \sim \vec{\pi^*}$, entonces la distribuci\'on del primer estado es igual a la distribuci\'on estacionaria, \ie que $X_1 \sim \vec{\pi^*}$, lo que a su vez implica que la distribuci\'on del segundo estado es igual a la distribuci\'on estacionaria, \ie que $X_2 \sim \vec{\pi^*}$, y asi sucesivamente. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

C\'alculo de la Distribuci\'on en Estado Estable: 
\begin{enumerate}
\item Escribimos una ecuaci\'on para cada uno de los $n$ estados: 
\[
\forall e \colon \, \vec{\pi}(e) \; = \; 
\sum_{\text{estados }x} \vec{\pi}(x) \, \vec{P}(x,e) 
\]
\item Desechamos arbitrariamente una de las $n$ ecuaciones anteriores y la reemplazamos por: 
\[
\sum_{\text{estados }e} \vec{\pi}(e) \; = \; 1
\]
\item Resolvemos el sistema de ecuaciones lineales resultante, el cual tiene \linebreak $n$ inc\'ognitas y $n$ ecuaciones linealmente independientes. 

\end{enumerate}

\end{frame}

% =================================================================
\subsection{Estados Transitorios y Recurrentes}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Algunas definiciones:
\begin{itemize}
\item Un \textbf{camino} desde el estado $i$ hasta el estado $j$ es una secuencia finita de estados que empieza en el estado $i$ y termina en el estado $j$ donde cada transici\'on entre estados a lo largo del camino tiene probabilidad positiva. 
\item El estado $i$ puede \textbf{alcanzar} al estado $j$ si existe al menos un camino \linebreak desde $i$ hasta $j$. 
\item Un par de estados $i,j$ se \textbf{comunican} si el estado $i$ puede alcanzar al \linebreak estado $j$ y vice-versa. 
\item Un estado $i$ es \textbf{transitorio} si puede alcanzar otro estado $j$ tal que tal que \linebreak el estado $i$ no puede ser alcanzado desde el estado $j$. 
\item Un estado $i$ es \textbf{recurrente} si no es transitorio. 
\begin{itemize}
\item Toda cadena de Markov tiene al menos un estado recurrente. 
\end{itemize}
\framebreak
\item Un estado $i$ es \textbf{absorbente} si es recurrente y adem\'as no puede ser abandonado una vez que ocurre. 
\item Un subconjunto de estados es una \textbf{clase recurrente} si:
\begin{itemize}
\item Todos sus estados son recurrentes. 
\item Todo par de estados en la clase se comunican. 
\end{itemize}
\item Un estado $i$ tiene \textbf{per\'iodo $k$} si todo camino de retorno al estado tiene una longitud igual al alg\'un m\'ultiplo de $k$. M\'as formalmente:
\[
k \, = \, \text{MCD} \{ \, n \geq 1 \colon \Pr( \, X_n = i \mid X_0 = i \, ) > 0 \, \}
\]
Adem\'as, si $k = 1$ entonces decimos que el estado es \textbf{aperi\'odico}. 
\item Una cadena es \textbf{aperi\'odica} si tiene al menos un estado aperi\'odico. 
\framebreak
\item Decimos que una cadena es \textbf{irreducible} o es una \textbf{uni-cadena} si: 
\begin{itemize}
\item Es aperi\'odica. 
\item Todos sus estados pertenecen a una \'unica clase recurrente. 
\end{itemize}
\end{itemize}
\fullskip

Algunos resultados generales:
\begin{itemize}
\item Si una cadena es aperi\'odica entonces tiene al menos una distribuci\'on en estado estable; caso contrario, la cadena no puede tener ninguna \linebreak distribuci\'on en estado estable. 
\item Para el caso de cadenas aperi\'odicas, sin importar si existe una o m\'as distribuciones en estado estable, todas las distribuciones en estado estable \linebreak le asignan cero probabilidad a los estados transitorios. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Algunos resultados para cadenas con \textbf{una sola clase recurrente:}
\begin{itemize}
\item La distribuci\'on en estado estable existe, es \'unica, y no depende de la distribuci\'on del estado inicial. 
\item Todo estado recurrente tiene probabilidad en estado estable positiva. 
\end{itemize}
\fullskip

Algunos resultados para cadenas con \textbf{m\'as de una clase recurrente:}
\begin{itemize}
\item La distribuci\'on en estado estable existe pero no es \'unica y depende de la distribuci\'on del estado inicial. 
\item Todo estado recurrente que puede ser alcanzado desde el estado inicial \linebreak tiene probabilidad en estado estable positiva, la cual puede ser computada por propagaci\'on de distribuciones. 
\end{itemize}


\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\textbf{Ejercicio en Clase:}
\begin{itemize}
\item H\&L Problema 16.5-4
\item H\&L Problema 16.5-1
\end{itemize}
\fullskip

\textbf{Ejercicio en Clase:}
\begin{itemize}
\item H\&L Problema 16.4-1
\item H\&L Problema 16.4-2
\item H\&L Problema 16.4-3
\item H\&L Problema 16.4-4
\item H\&L Problema 16.4-5
\end{itemize}

\end{frame}

% =================================================================
\section{Cadenas de Markov de Tiempo Continuo}

% =================================================================
\subsection{Modelamiento}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Una \textbf{Cadena de Markov de Tiempo Continuo} es un modelo matem\'atico de un proceso estoc\'astico en tiempo continuo constitu\'ido por: 
\begin{itemize}
\item Conjunto finito de $n$ estados, donde cada estado es una representaci\'on de una posible situaci\'on de inter\'es. 
\item Matriz de tasas de transici\'on $\vec{Q} \in \Re^{n \times n}$, donde: 
\begin{itemize}
\item Para todo estado $i$ tenemos que $\vec{Q}(i,i) = 0$. 
\item La tasa de salida del estado $i$ se define como: 
\[
\vec{Q}(i) \; \define \; \sum_{ 1 \leq j \leq n } \vec{Q}(i,j)
\]
\framebreak
\item Cada vez que la cadena ingresa a un estado $i$ la duraci\'on del intervalo \linebreak durante el cual la cadena permanece en ese estado, denotado $T_i$, es una variable aleatoria con distribuci\'on exponencial. M\'as precisamente: 
\[
T_i \, \sim \, \Exponential \, ( \, \vec{Q}(i) \, )
\]
\item Para cada par de estados $i,j$: 
\[
\vec{P}(i,j) \; = \; 
\Pr \, ( \, \text{siguiente estado sea } j \mid \text{estado actual es } i \, ) \; = \; 
\frac{ \vec{Q}(i,j) }{ \; \vec{Q}(i) \; }
\]
\item Observe adem\'as que para cualquier estado $i$ la sumatoria de las tasas de transici\'on $\vec{Q}(i,j)$ es positiva pero generalmente diferente de uno. 
\end{itemize}
\end{itemize}

\end{frame}

% =================================================================
\subsection{Distribuci\'on en Estado Estable}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

C\'alculo de la Distribuci\'on en Estado Estable: 
\begin{enumerate}
\item Escribimos una ecuaci\'on para cada uno de los $n$ estados: 
\[
\forall j \colon \, \vec{\pi}(j) \, \vec{Q}(j) \; = \; 
\sum_{\text{estados }i} \vec{\pi}(i) \, \vec{Q}(i,j) 
\]
\item Desechamos arbitrariamente una de las $n$ ecuaciones anteriores y la reemplazamos por: 
\[
\sum_{\text{estados }e} \vec{\pi}(e) \; = \; 1
\]
\item Resolvemos el sistema de ecuaciones lineales resultante, el cual tiene \linebreak $n$ inc\'ognitas y $n$ ecuaciones linealmente independientes. 

\end{enumerate}

\end{frame}

\end{document}
