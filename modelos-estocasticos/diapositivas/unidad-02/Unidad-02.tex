% =================================================================
\documentclass[ 10pt, xcolor = dvipsnames]{beamer}
\usepackage{ beamerthemesplit, lmodern}
\usetheme{Madrid}
\usecolortheme[named=Brown]{structure}
\useinnertheme{rectangles}
\setbeamertemplate{frametitle continuation}{}
\beamertemplatenavigationsymbolsempty
\graphicspath{{./figures/}}
\usepackage{../../../macros-general}
\usepackage{../../../macros-beamer}
\input{../../../beamer_section-slides}

% =================================================================
\newcommand{\shorttitle}{Modelos Estoc\'asticos - Unidad 02}
\title[\shorttitle]{Modelos Estoc\'asticos para Manufactura y Servicios (INDG-1008): \textbf{Unidad 02} }
\author[L. I. Reyes Castro]{Luis I. Reyes Castro}
\institute[ESPOL]{\normalsize Escuela Superior Polit\'ecnica del Litoral (ESPOL) \\ Guayaquil - Ecuador}
\date[2017-T1]{2017 - Primer T\'ermino}

% -----------------------------------------------------------------
\begin{document}
\input{../../../beamer_table-contents}
\input{../../../macros-espanol}

% =================================================================
\section{Repaso de Variables Aleatorias}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

Una variable aleatoria es un modelo de una cantidad escalar incierta. Para definir una variable aleatoria, digamos $X$, se requieren dos elementos: 
\begin{itemize}
\item Un \emph{soporte}, el cual es el conjunto de todos los valores que puede tomar la variable aleatoria. 
\item Una \emph{funci\'on de probabilidad} que depende de la naturaleza de la variable: 
\begin{itemize}
\item Si $X$ es una variable aleatoria discreta entonces su \emph{masa} probabil\'istica, denotada $p_X$, es una funci\'on tal que: 
\[
\forall \, x \in \support(X) \colon \; p_X(x) \geq 0 \, ;
\qquad
\sum_{x \in \support(X)} p_X(x) \; = \; 1
\]
\item Si $X$ es una variable aleatoria continua entonces su \emph{densidad} probabil\'istica, denotada $f_X$, es una funci\'on tal que: 
\[
\forall \, x \in \support(X) \colon \; f_X(x) \geq 0 \, ;
\qquad
\int_{x \in \support(X)} f_X(x) \, dx \, \; = \; 1
\]
\end{itemize}
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Valor Esperado:}
\begin{itemize}
\item Si $X$ es una variable aleatoria discreta entonces 
\[
\Exp[X] \, = \, \sum_{ x \, \in \, \support(X) } x \, \Pr(x)
\]
donde la sumatoria es sobre todos los valores que puede tomar $X$. 
\item Si $X$ es una variable aleatoria continua entonces 
\[
\Exp[X] \, = \, \int_{ x \, \in \, \support(X) } x \, f(x) \, dx
\]
donde la integraci\'on es sobre todos los valores que puede tomar $X$. 
\item Si $X,Y$ son variables aleatorias y $a,b$ son constantes entonces: 
\[
\Exp[ \, a X + b Y \, ] \, = \, a \, \Exp[X] + b \, \Exp[Y]
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Independecia de Variables Aleatorias:}
\begin{itemize}
\item Decimos que las variables aleatorias discretas $X,Y$ son independientes si \linebreak para todo posible par de valores $(x,y)$ que las variables aleatorias \linebreak pueden tomar es el caso que: 
\[
\Pr( \, X = x, \, Y = y \, ) \, = \,
\Pr( \, X = x \, ) \, \Pr( \, Y = y \, )
\]
\item Si $X,Y$ son variables aleatorias independientes entonces: 
\[
\Exp[XY] \, = \, \Exp[X] \, \Exp[Y]
\]
N\'otese que esta relaci\'on en general no es v\'alida par variables aleatorias dependientes. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\begin{itemize}
\item Si $X,Y$ son dos variables aleatorias entonces la probabilidad del valor $x$ de la primera variable condicional en el valor $y$ de la segunda esta dado por: 
\[
\Pr( \, X = x \mid Y = y \, ) \, = \, 
\frac{ \Pr( \, X = x, \, Y = y ) }{ \Pr( \, Y = y \, ) }
\]
\item Claramente, si $X,Y$ son variables aleatorias independientes entonces para todo valor $x$ de la primera variable y todo valor $y$ de la segunda: 
\[
\Pr( \, X = x \mid Y = y \, ) \, = \, \Pr( \, X = x \, )
\]
\framebreak
\item Si $X,Y$ son dos variables aleatorias entonces para todo valor $y$ de la \linebreak segunda variable aleatoria: 
\[
\Exp[ \, X \mid Y  = y \, ] \, = \, \sum_{ x \, \in \, \support( X \mid Y = y ) } x \, \Pr( \, X = x \mid \, Y = y )
\]
\item Si $X,Y$ son dos variables aleatorias entonces: 
\[
\Exp[X] \, = \, \Exp[ \, \Exp[ \, X \mid Y \, ] \, ] \, = \, 
\sum_{ y \, \in \, \support(Y) } \Exp[ \, X \mid Y = y \, ] \,
\Pr( \, Y = y \, )
\]

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Bernoulli:}
\begin{itemize}
\item La variable aleatoria $\Bernoulli(p)$ representa la ocurrencia o no ocurrencia \linebreak de alg\'un evento de inter\'es que sucede con probabilidad $p$, \eg el resultado de lanzar una moneda sesgada. 
\item Si $X \sim \Bernoulli(p)$ entonces su distribucion es: 
\[
\Pr( \, X = 0 \, ) \, = 1 - p \qquad \qquad \qquad
\Pr( \, X = 1 \, ) \, = p
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, p \qquad \qquad \qquad
\var(X) \, = \, p \, (1-p)
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Binomial:}
\begin{itemize}
\item La variable aleatoria $\Binomial(n,p)$ representa el n\'umero de ensayos exitosos en un experimento que involucra $n$ ensayos independientes donde uno de los cuales tiene \'exito con probabilidad $p$. 
\item Alternativamente, puede ser reconocida como la suma de variables aleatorias Bernoulli independientes e id\'enticamente distrib\'idas. \Ie si $X_1, \dots, X_n$ son variables i.i.d. con distribuci\'on $\Bernoulli(p)$ entonces: 
\[
Z = X_1 + \cdots + X_n \qquad \Longrightarrow \qquad
Z \sim \Binomial(n,p)
\]
\framebreak
\item Si $Z \sim \Binomial(n,p)$ entonces su distribucion es: 
\[
\forall \, k \in \{ \, 0, \, 1, \, \dots, \, n \} \; \colon \;
\Pr( \, Z = k \, ) \; = \; {n \choose k} p^k \, (1-p)^{n-k}
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, n \, p \qquad \qquad \qquad
\var(X) \, = \, n \, p \, (1-p)
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Geom\'etrica:}
\begin{itemize}
\item Tenemos dos tipos. Yo las denoto aqu\'i como $\Geo(p)_0$ y $\Geo(p)_1$ pero son realmente la misma variable aleatoria pues: 
\[
\Geo(p)_0 + 1 \; \sim \; \Geo(p)_1
\]

\item Para interpretarlas consideraremos una secuencia de experimentos independientes, donde cada uno tiene \'exito con probabilidad $p$, \linebreak que concluye con el primer experimento exitoso. 
\framebreak

\item La variable aleatoria $\Geo(p)_0$ representa el n\'umero de experimentos fallidos que transcurrieron antes del primer experimento exitoso. 
\begin{itemize}
\item Si $X \sim \Geo(p)_0$ entonces su distribucion es: 
\[
\forall \, k \geq 0 \; \colon \;
\Pr( \, X = k \, ) \; = \; (1-p)^k \, p
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \frac{1-p}{p} \qquad \qquad \qquad
\var(X) \, = \, \frac{1-p}{p^2}
\]
\end{itemize}
\framebreak

\item La variable aleatoria $\Geo(p)_1$ representa la longitud de la secuencia de experimentos, \ie el n\'umero de experimentos realizados. 
\begin{itemize}
\item Si $X \sim \Geo(p)_1$ entonces su distribucion es: 
\[
\forall \, k \geq 1 \; \colon \;
\Pr( \, X = k \, ) \; = \; (1-p)^{k-1} \, p
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \frac{1}{p} \qquad \qquad \qquad
\var(X) \, = \, \frac{1-p}{p^2}
\]
\end{itemize}

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Exponencial:}
\begin{itemize}
\item La variable aleatoria $\Exponential(\lambda)$ es com\'unmente utilizada para modelar los tiempos entre arribos o eventos de inter\'es en un proceso estoc\'astico en tiempo continuo. 
\item Si $X \sim \Exponential(\lambda)$ entonces su distribucion es: 
\[
\forall \, t \geq 0 \; \colon \;
f_X(t) \; = \; \lambda \, e^{ -\lambda t}
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \frac{1}{\lambda} \qquad \qquad \qquad
\var(X) \, = \, \frac{1}{\lambda^2}
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Ejercicio - H\&L Problema 17.4-3:}

El tiempo que requiere un mec\'anico para reparar una m\'aquina tiene una distribuci\'on exponencial con media de 4 horas. Sin embargo, una herramienta especial reducir\'ia esta media a 2 horas. Si el mec\'anico repara una m\'aquina en menos de 2 horas, se le pagan
\$100; de otra manera se le pagan \$80. Determine el aumento esperado en el pago del mec\'anico si usa esta herramienta especial. 

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Variable Aleatoria Poisson:}
\begin{itemize}
\item La variable aleatoria $\Poisson(\mu)$ es com\'unmente utilizada para modelar el n\'umero de arribos o eventos de inter\'es en un proceso estoc\'astico a lo largo de un intervalo de tiempo. 
\item Si $X \sim \Poisson(\mu)$ entonces su distribucion es: 
\[
\forall \, k \geq 0 \; \colon \;
\Pr( \, X = k \, ) \; = \; \frac{\mu^k \, e^{-\mu} }{k!}
\]
\item Adicionalmente, su valor esperado y varianza son: 
\[
\Exp[X] \, = \, \mu \qquad \qquad \qquad
\var(X) \, = \, \mu
\]
\end{itemize}

\end{frame}

% =================================================================
\section{Proceso Bernoulli}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Ejemplo aleatorio:}

En una f\'abrica una m\'aquina tiene un componente que usualmente debe ser reemplazado. A pesar de que reemplazar el componente toma unos pocos minutos al final de la jornada de trabajo, cada d\'ia de operaci\'on de la m\'aquina el componente se puede da\~nar con probabilidad $p$, independientemente de lo que haya pasado antes. Con esto en mente: 
\begin{itemize}
\item Cu\'antas veces a la semana, en promedio, tendr\'an que reemplazar el componente? 
\item Si han pasado cuatro d\'ias desde la \'ultima vez que se cambi\'o en componente, cu\'al es la probabilidad de que se da\~ne ma\~nana? 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Proceso Bernoulli con Par\'ametro $p$:}
\begin{itemize}
\item Es una secuencia de variables aleatorias Bernoulli con par\'ametro $p$ independientes e ind\'enticamente distribuidas que representan la \linebreak presencia o ausencia de arribos. 
\item Formalmente es una secuencia de variables aleatorias $X_1, \, X_2, \, X_3, \, X_4, \, \dots$ donde: 
\begin{itemize}
\item Para todo \'indice $i$ tenemos que $X_i \sim \Bernoulli(p)$. 
\item Para todo par de \'indices $i,j$ es el caso que $X_i$ es independiente de $X_j$. 
\end{itemize}
\item Consideramos que ocurre un arribo en el per\'iodo $t$ si $X_t = 1$; caso contrario no ocurri\'o un arribo en ese per\'iodo. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Tiempos Entre Arribos:}
\begin{itemize}
\item Para todo \'indice $i \geq 1$ la variable aleatoria $T_i$ representa el n\'umero de per\'iodos que transcurrieron desde el $(i-1)$\tsup{avo} arribo hasta el $i$\tsup{avo} arribo. 
\begin{itemize}
\item N\'otese que $\support(T_i) = \ZNN$. 
\end{itemize}
\item Cu\'al es la distribuci\'on de $T_1$? \Ie para cada n\'umero de per\'iodos $k \in \ZNN$, cu\'al es la probabilidad de que $T_1 = k$? 
\begin{itemize}
\item Claramente $k = 0$ con probabilidad $p$. 
\item Si $k = 1$ entonces $X_1 = 0$ y $X_2 = 1$, \ie en el primer per\'iodo no hubo un arribo y en el segundo per\'iodo hubo un arribo, lo cual sucede con \linebreak probabilidad $(1-p) \, p$. 
\item Si $k = 2$ entonces $X_1 = 0$, $X_2 = 0$ y $X_3 = 1$, lo cual sucede con \linebreak probabilidad $(1-p)^2 \, p$. 
\end{itemize}
\framebreak
\item Continuando por inducci\'on matem\'atica, vemos que: 
\[
\forall \, k \in \ZNN \; \colon \; 
\Pr( \, T_1 = k \, ) \, = \, (1-p)^k \, p 
\quad \Longleftrightarrow \quad T_1 \sim \Geo(p)_0
\]
\item M\'as generalmente, en un proceso Bernoulli con par\'ametro $p$ los tiempos entre arribos constituyen una secuencia de variables aleatorias independientes e identicamente distribuidas; en particular, con distribuci\'on geom\'etrica-0. \Iec
\[
\forall \, i \geq 1 \; \colon \; T_i \sim \Geo(p)_0
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Propiedad Sin Memoria del Proceso Bernoulli:}
\begin{itemize}
\item Sup\'ongase que ha empezado el proceso y han transcurrido $t$ per\'iodos sin un arribo, \ie $t < T_1$. Cu\'al es la probabilidad de que haya que esperar $\tau \geq 1$ per\'iodos adicionales hasta el primer arribo? \Iec
\[
\tau \geq 1 \; \colon \; \Pr( \, T_1 = t + \tau \mid T_1 > t \, )
\]
\item Puesto que la variable aleatoria $T_1 \sim \Geo(p)_0$, \ie el n\'umero de per\'iodos que transcurrieron hasta el primer arribo tiene distribuci\'on geom\'etrica, y dado que en general para todo $i \geq 1$ es el caso que $T_i \sim \Geo(p)_0$, es f\'acil demostrar que,para todo \'indice de arribo $i \geq 1$ tenemos que $T_i \sim \Geo(p)_0$ para todo $i \geq 1$ : 
\[
\forall \, t \geq 1, \; \forall \, \tau \geq 1 \; \colon \;
\Pr( \, T_i = t + \tau \mid T_i > t \, ) \; = \;
\Pr( \, T_i = \tau \, )
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{N\'umero de Arribos en un Intervalo:}
\begin{itemize}
\item Si para todo \'indice $k$ denotamos a la variable aleatoria $N_k$ como el n\'umero \linebreak de arribos desde el comienzo del proceso hasta el $k$\tsup{avo} periodo, entonces: 
\[
N_k \, = \, \sum_{t=1}^k X_t
\]
\Ie la variable aleatoria $N_k$ es la suma de $k$ variables aleatorias Bernoulli con par\'ametro $p$ independientes e identicamente distribuidas (IID). Consecuentemente: 
\[
N_k \sim \Binomial(k,p)
\]
\item M\'as generalmente, en un proceso Bernoulli con par\'ametro $p$ el n\'umero de arribos a lo largo de cualquier intervalo de $k$ per\'iodos de duraci\'on es una variable aleatoria con distribuci\'on binomial con par\'ametros $k$ y $p$. 
\end{itemize}

\end{frame}


% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Arribos en Intervalos Disjuntos:}
\begin{itemize}
\item En un proceso Bernoulli los n\'umeros de arribos a lo largo de intervalos de tiempo disjuntos son estad\'isticamente independientes. 
\end{itemize}
\fullskip

\textbf{Combinaci\'on de Procesos Bernoulli:}
\begin{itemize}
\item Supongamos que tenemos dos procesos Bernoulli independientes. 
\begin{itemize}
\item El primero tiene par\'ametro $p$. 
\item El segundo tiene par\'ametro $q$. 
\end{itemize}
\item Consideremos un nuevo proceso donde se produce un arribo si y solo si \linebreak ocurre un arribo en ambos procesos. 
\begin{itemize}
\item Los arribos en el nuevo proceso son independientes entre si, pues en cada per\'iodo solo dependen en los arribos de los procesos generadores, los cuales \linebreak no dependen de arribos en tiempos anteriores. 
\framebreak
\item La probabilidad de un arribo en el nuevo proceso es el producto de las probabilidades de arribo en cada proceso generador, pues los procesos generadores son independientes. 
\item En conclusi\'on el nuevo proceso es un proceso Bernoulli con par\'ametro $pq$. 
\end{itemize}
\item Consideremos un nuevo proceso donde se produce un arribo si y solo si \linebreak ocurre un arribo en alguno de los dos procesos. 
\begin{itemize}
\item Los arribos en el nuevo proceso son independientes entre si, pues en cada per\'iodo solo dependen en los arribos de los procesos generadores, los cuales \linebreak no dependen de arribos en tiempos anteriores. 
\item La probabilidad de un arribo en el nuevo proceso es uno menos la probabilidad de que no haya un arribo, la cual es el producto de las probabilidades de que no hayan arribos en cada uno de los procesos generadores, pues los procesos generadores son independientes. 
\item En conclusi\'on el nuevo proceso es un proceso Bernoulli con par\'ametro $1 - (1-p)(1-q)$. 
\end{itemize}

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Divisi\'on de Procesos Bernoulli:}
\begin{itemize}
\item Supongamos que tenemos un proceso Bernoulli con par\'ametro $p$ que genera dos procesos. 
\item En cada per\'iodo: 
\begin{itemize}
\item Si el proceso principal produce un arribo, lanzamos una moneda sesgada con probabilidad de cara igual a $q$. 
\item Si la moneda sale cara enviamos el arribo al primer proceso. 
\item Si la moneda sale sello enviamos el arribo al segundo proceso. 
\end{itemize}
\item Entonces: 
\begin{itemize}
\item El primer proceso ser\'a un proceso Bernoulli con par\'ametro $p \, q$. 
\item El segundo proceso ser\'a un proceso Bernoulli con par\'ametro $p \, (1-q)$. 
\end{itemize}
\end{itemize}

\end{frame}

% =================================================================
\section{Proceso Poisson}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Proceso Poisson con par\'ametro $\lambda$:}
\begin{itemize}
\item Es una secuencia de variables aleatorias exponenciales con par\'ametro $\lambda$ independientes e ind\'enticamente distribuidas que representan los tiempos entre arribos (no los tiempos de los arribos). 
\item Formalmente es una secuencia de variables aleatorias $X_1, \, X_2, \, X_3, \, X_4, \, \dots$ donde: 
\begin{itemize}
\item Para todo \'indice $i$ tenemos que $X_i \sim \Exponential(\lambda)$. 
\item Para todo par de \'indices $i,j$ es el caso que $X_i$ es independiente de $X_j$. 
\end{itemize}
\item El proceso empieza en el tiempo cero, \ie $t = 0$, el primer arribo ocurre en \linebreak el tiempo $t = X_1$, el segundo en el tiempo $t = X_1 + X_2$, y as\'i sucesivamente; \ie el $k$\tsup{avo} arribo ocurre en: 
\[
t \, = \, X_1 + X_2 + \cdots + X_k
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Propiedades del Proceso Poisson (con par\'ametro $\boldsymbol{\lambda}$):}
\begin{itemize}
\item \underline{Tiempos de los Arribos:} Para todo \'indice $k \geq 1$ el tiempo del $k$\tsup{avo} arribo tiene distribuci\'on Erlang con par\'ametros $k$ y $\lambda$. 
\item \underline{Propiedad Sin Memoria:} En cada periodo la distribuci\'on del tiempo que falta para el siguiente arribo es independiente del tiempo transcurrido desde el \'ultimo arribo. M\'as formalmente, para todo \'indice de arribo $k \geq 1$ : 
\[
\forall \; t, \, \tau > 0 \; \colon \;
\Pr( \, X_k > t + \tau \mid X_k > t \, ) \; = \;
\Pr( \, X_k > \tau \, )
\]
\item \underline{N\'umero de Arribos en un Intervalo:} El n\'umero de arribos en un intervalo de $\tau$ unidades es una variable aleatoria Poisson con par\'ametro $\lambda \, \tau$. 
\item \underline{Arribos en Intervalos Disjuntos:} Si dos intervalos de tiempo son disjuntos entonces el n\'umero de arribos durante esos intervalos son independientes. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Ejercicio - H\&L Problema 17.4-2:}

Los trabajos que deben realizarse en una m\'aquina espec\'ifica llegan de acuerdo con un proceso de entradas de Poisson con tasa media de 2 por hora. Suponga que la m\'aquina se descompone y su reparaci\'on tardar\'a 1 hora. Cu\'al es la probabilidad de que el n\'umero de trabajos que lleguen durante este tiempo sea: 
\begin{itemize}
\item Cero?
\item Dos?
\item Cinco o m\'as?
\end{itemize}

\framebreak

\underline{Ejercicio - Taha Problema 18.3A-3:}

El tiempo entre llegadas a la Oficina Estatal de Hacienda es exponencial, \linebreak con valor medio de .05 horas. La oficina abre a las 8:00 A.M. 
\begin{enumerate}
\item Cu\'al es la distribuci\'on del tiempo entre llegadas?
\item Encuentre la probabilidad de que hasta las 8:15 todav\'ia no haya llegado ningun cliente. 
\item En este momento son las 8:35. El \'ultimo cliente lleg\'o a la oficina a la 8:26. Cu\'al es la probabilidad de que el siguiente cliente llegue antes de las 8:38? De que no llegue alrededor de las 8:40?
\item Cu\'al es el promedio de clientes que llegan entre las 8:10 y las 8:45?
\end{enumerate}

\framebreak

\underline{Ejercicio - Taha Problema 18.3A-7:}

Ann y Jim, dos empleados en un restaurante de comida r\'apida, efect\'uan el siguiente juego mientras esperan que lleguen clientes: Jim le paga a Ann 2 centavos si el siguiente cliente no llega dentro de 1 minuto; de lo contrario, \linebreak Ann le paga a Jim 2 centavos. Determine la ganancia promedio de Jim en un periodo de 8 horas. El tiempo entre llegadas es exponencial con media de 1.5 minutos. 

\framebreak

\underline{Ejercicio - Taha Problema 18.3A-10:}

Un cliente que llega a un restaurante de comida r\'apida McBurger dentro de 4 minutos del cliente inmediatamente anterior recibir\'a 10\% de descuento. \linebreak Si el tiempo entre llegadas es de entre 4 y 5 minutos, el descuento es de 6\%. \linebreak Si el tiempo entre llegadas es de m'as de 5 minutos, el cliente obtiene 2\% de descuento. El tiempo entre llegadas es exponencial con una media de 6 minutos. 

\framebreak

\underline{Ejercicio - Taha Problema 18.3A-12:}

La U de A opera dos l\'ineas de autobuses en el campus: roja y verde. La l\'inea roja presta servicio al norte del campus, y la verde al sur del campus, con una estaci\'on de transferencia que une las dos rutas. Los autobuses verdes llegan al azar (tiempo entre llegadas exponencial) a la estaci\'on de transferencia cada 10 minutos. Los autobuses rojos tambi\'en lo hacen al azar cada 7 minutos. 

Con esto en mente: 
\begin{itemize}
\item Cu\'al es la distribuci\'on del tiempo de espera de un estudiante que llega en la l\'inea roja para abordar la l\'inea verde? 
\item Cu\'al es la distribuci\'on del tiempo de espera de un estudiante que llega en la l\'inea verde para abordar la l\'inea roja? 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Combinaci\'on de Procesos Poisson:}
\begin{itemize}
\item Supongamos que tenemos dos procesos independientes. 
\begin{itemize}
\item El primero es un proceso Poisson con par\'ametro $\lambda_1$.
\item El segundo es un proceso Poisson con par\'ametro $\lambda_2$.
\end{itemize}
\item Entonces, si consideremos un nuevo proceso que combina los arribos de \linebreak los dos procesos anteriores, el nuevo proceso es de hecho un \linebreak proceso Poisson con par\'ametro:
\[
\lambda_1 + \lambda_2
\]
De manera similar, si combinamos $n$ processos Poisson con par\'ametros $\lambda_1, \lambda_2, \dots, \lambda_n$ entonces el proceso combinado ser\'a un proceso Poisson \linebreak con par\'ametro: 
\[
\lambda_1 + \lambda_2 + \cdots + \lambda_n
\]
\item Adicionalmente, para cualquier arribo en el proceso combinado la probabibilidad de que ese arribo provenga del proceso $k \in \{ 1, 2 \}$ es: 
\[
\frac{\lambda_k}{ \lambda_1 + \lambda_2 }
\]
Similarmente, si combinamos $n$ processos Poisson como antes entonces la probabilidad de que un arribo en el proceso combinado haya provenido del $k$\tsup{avo} proceso es: 
\[
\frac{\lambda_k}{ \lambda_1 + \lambda_2 + \cdots + \lambda_n }
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\textbf{Divisi\'on de Procesos Poisson:}
\begin{itemize}
\item Supongamos que tenemos un proceso Poisson con par\'ametro $\lambda$ que genera dos procesos de tal manera que en cada instante: 
\begin{itemize}
\item Si el proceso principal produce un arribo, lanzamos una moneda sesgada con probabilidad de cara igual a $p$. 
\item Si la moneda sale cara enviamos el arribo al primer proceso. 
\item Si la moneda sale sello enviamos el arribo al segundo proceso. 
\end{itemize}
\item Entonces: 
\begin{itemize}
\item El primer proceso ser\'a un proceso Poisson con par\'ametro $\lambda \, p$. 
\item El segundo proceso ser\'a un proceso Poisson con par\'ametro $\lambda \, (1-p)$. 
\end{itemize}
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsection}

\underline{Ejercicio - H\&L Problema 17.4-5:}

Un sistema de colas tiene tres servidores con tiempos de servicio esperados de 30, 20 y 15 minutos. Los tiempos de servicio tienen una distribuci\'on exponencial. Cada servidor ha estado ocupado con el cliente actual durante 10 minutos. 

Determine el tiempo esperado que falta para la siguiente terminaci\'on de un servicio. 

\framebreak

\underline{Ejercicio - H\&L Problema 17.4-6:}

Considere un sistema de colas con dos tipos de clientes. Los clientes tipo 1 llegan de acuerdo con un proceso de Poisson a una tasa media de 5 por hora, mientras que los clientes tipo 2 llegan de acuerdo a un proceso de Poisson a una tasa media de 5 por hora. El sistema tiene dos servidores, que atienden a ambos tipos de clientes. Para los dos tipos el tiempo de servicio tiene una distribuci\'on exponencial con media de 10 minutos. El servicio es tipo primero en entrar, primero en salir. 

Cu\'al es la distribuci\'on (y su media) del tiempo entre llegadas consecutivas de clientes de cualquier tipo?

\framebreak

\underline{Ejercicio:}

El call center de una empresa de servicios al consumidor recibe en promedio, $\lambda_1 = 11.9$ llamadas por hora para Servicio al Cliente y $\lambda_2 = 21.4$ llamadas por hora para Servicio T\'ecnico. De los clientes que llaman para Servicio al Cliente el $p_{12} = 5.3\%$ es referido a Servicio T\'ecnico, mientras que de los clientes que llaman a Servicio T\'ecnico el $p_{21} = 17.6\%$ es referido a Servicio al Cliente.

Con esto en mente, calcule el n\'umero promedio de clientes por hora que debe atender el departamento de Servicio al Cliente y el deparatamento de \linebreak Servicio T\'ecnico. 

\end{frame}

% =================================================================
\section{Cadenas de Markov}

% =================================================================
\subsection{Modelamiento}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Una \textbf{Cadena de Markov} es un modelo matem\'atico de un proceso estoc\'astico \linebreak en tiempo discreto constitu\'ido por: 
\begin{itemize}
\item Conjunto finito de $n$ estados, donde cada estado es una representaci\'on de una posible situaci\'on de inter\'es. 
\item Matriz de transici\'on $\vec{P} \in \Re^{n \times n}$, donde: 
\begin{itemize}
\item Para cada par de estados $i,j$: 
\[
\vec{P}(i,j) \, = \, 
\Pr \, ( \, 
\text{siguiente estado sea } j \mid
\text{estado actual es } i \, )
\]
\item Cada una de las filas de la matriz suman a uno. 
\end{itemize}
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejercicio - H\&L Secci\'on 16.1 (Ejemplo del Clima):}

El clima en el pueblo de Centerville puede cambiar con rapidez de un d\'ia a otro. Sin embargo, las posibilidades de tener clima seco (sin lluvia) ma\~nana es de alguna forma mayor si hoy est\'a seco, es decir, si no llueve. En particular, \linebreak la probabilidad de que ma\~nana este seco es de 0.8 si hoy est\'a seco, pero \linebreak es de solo 0.6 si hoy llueve. Estas probabilidades no cambian si se considera \linebreak la informaci\'on acerca del clima en los d\'ias anteriores a hoy. 

Modele este proceso clim\'atico como una Cadena de Markov. 
\framebreak

Estados: 
\begin{enumerate}
\item Est\'a seco
\item Llueve
\end{enumerate}

Matriz de transici\'on:
\[
\vec{P} \, = \, 
\left[
\begin{array}{cc}
0.8 & 0.2 \\ 0.6 & 0.4
\end{array}
\right]
\]

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejercicio - H\&L Secci\'on 16.1 (Ejemplo de Inventarios):}

La tienda de fotograf\'ia de Dave se admministra semanalmente y est\'a abierta al p\'ublico desde el lunes en la ma\~nana hasta el s\'abado en la noche. Dave tiene en almac\'en un modelo especial de c\'amara que se vende relativamente bien. \linebreak Sean $D_1, \, D_2, \, D_3, \dots$ las demandas semanales de la c\'amara en unidades, \linebreak \ie el n\'umero de unidades que se vender\'ian si el inventario fuere inagotable. \linebreak M\'as precisamente, suponga que las demandas $D_t$ son variables aleatorias i.i.d. \linebreak que siguen una distribuci\'on Poisson con par\'ametro $\lambda = 1$. 

Dave maneja el inventario de acuerdo a la siguiente pol\'itica:
\begin{itemize}
\item Si no hay unidades de la c\'amara en inventario, se hace un pedido al proveedor por tres unidades. En este caso, el proveedor entregar\'a el pedido \linebreak el lunes a primera hora, justo antes de que la tienda abra. 
\item Caso contrario, no se hace un pedido. 
\end{itemize}
\framebreak

Definiendo a los cuatro posibles n\'umero de c\'amaras en inventario al final de cada semana como los estados, modele la pol\'itica de inventario descrita como una Cadena de Markov. 

Por si acaso, el orden de las actividades de la \tava semana es: 
\begin{enumerate}
\item Si se hizo un pedido al proveedor de las c\'amaras al final de la \linebreak \tmava semana se reciben las unidades que se pidieron. 
\item Se abre la tienda desde el lunes en la ma\~nana hasta el s\'abado en la noche. Durante este tiempo se venden entre cero y tres c\'amaras. 
\item Se cierra la tienda. 
\item De ser necesario, se hace un pedido al proveedor de las c\'amaras. 
\end{enumerate}
\framebreak

Estados: 
\begin{enumerate}
\item Quedan 0 unidades en inventario al final de la semana
\item Quedan 1 unidades en inventario al final de la semana
\item Quedan 2 unidades en inventario al final de la semana
\item Quedan 3 unidades en inventario al final de la semana
\end{enumerate}

Matriz de transici\'on:
\[
\vec{P} \, = \, 
\left[
\begin{array}{cccc}
0.08 & 0.18 & 0.37 & 0.37 \\
0.63 & 0.37 & 0    & 0    \\
0.26 & 0.37 & 0.37 & 0    \\
0.08 & 0.18 & 0.37 & 0.37
\end{array}
\right]
\]

\framebreak

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejercicio - H\&L Secci\'on 16.2 (Ejemplo de Acciones 1):}

En un mercado de valores existe una acci\'on que solo puede subir o bajar de precio. Si la acci\'on subi\'o hoy, la probabilidad de que suba ma\~nana es de 0.7. \linebreak En cambio, si la acci\'on baj\'o hoy, la probabilidad de que suba ma\~nana es de \linebreak solo 0.5. 

Modele el comportamiento de esta acci\'on como una Cadena de Markov. 

\framebreak

\underline{Ejercicio - H\&L Secci\'on 16.2 (Ejemplo de Acciones 2):}

Suponga ahora que el modelo del mercado de acciones se cambia de manera que el precio de la acci\'on ma\~nana depende del precio de ayer y de hoy. En particular, si la acci\'on subi\'o los dos d\'ias, ayer y hoy, la probabilidad de que suba ma\~nana es de 0.9. Si la acci\'on baj\'o ayer pero hoy subi\'o, la probabilidad de que ma\~nana suba es de 0.6. Si la acci\'on subi\'o ayer pero hoy baj\'o, la probabilidad de que ma\~nana suba es de 0.5. Por \'ultimo, si baj\'o durante estos dos d\'ias, la probabilidad de que ma\~nana suba es de 0.3. 

Modele el comportamiento de esta acci\'on como una Cadena de Markov. 

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejercicio:}

Un operador de servicios de telefon\'ia celular est\'a en proceso de instalar una antena en un barrio promedio, donde se puede esperar que la antena reciba un paquete de datos para su transmisi\'on durante cada ciclo (\eg durante cada milisegundo) con probabilidad $\lambda \in (0.99,1)$. Para poder satisfacer esta demanda se instal\'o un buffer con capacidad para $M$ paquetes de datos junto con $n$ transmisores que operan en canales independientes pero ruidosos; en particular, cada transmisor \linebreak que es encargado con el env\'io de un paquete logra transmitirlo exitosamente con probabilidad $\mu \in (0.94,0.98)$. Cuando una transmisi\'on fracasa se mantiene al paquete en el buffer y se reintenta la transmisi\'on en el siguiente per\'iodo. 

Cada ciclo de operaci\'on, digamos el \tavo ciclo, avanza de la siguiente manera: 
\begin{enumerate}
\item Se empieza el ciclo con $X_{t-1}$ paquetes en el b\'uffer. 
\framebreak
\item Si el buffer no est\'a lleno, se recibe un nuevo paquete con probabilidad $\lambda$, \linebreak de tal manera que el nuevo n\'umero de paquetes en el buffer es: 
\[
\min \; \{ \; X_{t-1} + D_t \, , \; M \, \} \, ,
\qquad \text{donde } D_t \sim \Bernoulli(\lambda)
\]
\item Los transmisores intentan enviar cuantos paquetes puedan. Si hay $n$ paquetes o m\'as en el buffer, entonces cada uno de los transmisores es asignado a un \'unico paquete, y cada transmisor logra enviar su paquete con \'exito con probabilidad $\mu$, independiente de los otros. Si hay menos de $n$ paquetes en \linebreak el buffer se opera de la misma manera, pero en este caso habr\'a uno o m\'as transmisores a los que no ser\'a necesario asignarles paquetes en este ciclo. 
\end{enumerate}

Con todo esto en mente, construya un modelo de Cadena de Markov de este proceso para el caso particular cuando $M = 5$ y $n = 3$. En particular, explique cuales son los estados y liste todas las probabilidades de transici\'on positivas. 

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\textbf{Definici\'on Formal de una Cadena de Markov:}
\begin{itemize}
\item Es una secuencia de variables aleatorias discretas $X_0, \, X_1, \, X_2, \, \dots, \, X_t, \, \dots$ \linebreak donde para cada \'indice de tiempo discreto $t$ la variable aleatoria $X_t$ \linebreak es el estado del proceso en el tiempo $t$. 
\item Tiene la \underline{Propiedad Markoviana}, \ie que la distribuci\'on del siguiente estado solo depende en el estado actual: 
\[
\Pr( \, X_{t+1} \mid X_{0}, \, X_{1}, \, \dots, \, X_t \, ) \; = \;
\Pr( \, X_{t+1} \mid X_{t} \, )
\]
\item En este contexto la matriz de transici\'on $\vec{P}$ se define como : 
\[
\vec{P}(i,j) \, = \,
\Pr( \, X_{t+1} = j \mid X_{t} = i \, )
\]
\end{itemize}

\end{frame}

% =================================================================
\subsection{Estados Transitorios y Recurrentes}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Algunas definiciones:
\begin{itemize}
\item Un \textbf{camino} desde el estado $i$ hasta el estado $j$ es una secuencia finita de estados que empieza en el estado $i$ y termina en el estado $j$ donde cada transici\'on entre estados a lo largo del camino tiene probabilidad positiva. 
\item El estado $i$ puede \textbf{alcanzar} al estado $j$ si existe al menos un camino \linebreak desde $i$ hasta $j$. 
\item Un par de estados $i,j$ se \textbf{comunican} si el estado $i$ puede alcanzar al \linebreak estado $j$ y vice-versa. 
\item Un estado $i$ es \textbf{transitorio} si puede alcanzar otro estado $j$ tal que tal que \linebreak el estado $i$ no puede ser alcanzado desde el estado $j$. 
\item Un estado $i$ es \textbf{recurrente} si no es transitorio. 
\begin{itemize}
\item Toda cadena de Markov tiene al menos un estado recurrente. 
\end{itemize}
\framebreak
\item Un estado $i$ es \textbf{absorbente} si es recurrente y adem\'as no puede ser abandonado una vez que ocurre. 
\item Un subconjunto de estados es una \textbf{clase recurrente} si:
\begin{itemize}
\item Todos sus estados son recurrentes. 
\item Todo par de estados en la clase se comunican. 
\end{itemize}
\item Un estado $i$ tiene \textbf{per\'iodo $k$} si todo camino de retorno al estado tiene una longitud igual al alg\'un m\'ultiplo de $k$. M\'as formalmente:
\[
k \, = \, \text{MCD} \{ \, n \geq 1 \colon \Pr( \, X_n = i \mid X_0 = i \, ) > 0 \, \}
\]
Adem\'as, si $k = 1$ entonces decimos que el estado es \textbf{aperi\'odico}. 
\item Una cadena es \textbf{aperi\'odica} si tiene al menos un estado aperi\'odico. 
\framebreak
\item Decimos que una Cadena de Markov es \textbf{irreducible}, es \textbf{erg\'odica}, o que es una \textbf{uni-cadena} si: 
\begin{itemize}
\item Es aperi\'odica. 
\item Todos sus estados pertenecen a una \'unica clase recurrente. 
\end{itemize}
\end{itemize}
\fullskip

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejercicios:}
\begin{itemize}
\item H\&L Problema 16.4-1
\item H\&L Problema 16.4-2
\item H\&L Problema 16.4-3
\item H\&L Problema 16.4-4
\item H\&L Problema 16.4-5
\end{itemize}

\end{frame}

% =================================================================
\subsection{Distribuci\'on Estacionaria}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejemplo aleatorio:}

Carlos es un aficionado del f\'utbol local quien, convenientemente, apoya a Barcelona o a Emelec dependiendo de cual de los dos equipos haya ganado el \'ultimo partido. Cuando Barcelona gana un partido, la probabilidad de que vuelva a ganar es del 60\%. En cambio, cuando Emelec gana la probabilidad de que vuelva a ganar es del 50\%. 

Modele el comportamiento de Carlos como una Cadena de Markov y encuentre la fracci\'on del tiempo que \'el apoya a cada equipo. 

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Todas las Cadenas de Markov que tienen una \'unica clase recurrente exhiben una \textbf{distribuci\'on estacionaria}, tambi\'en conocida como distribuci\'on en estado estable. Esta distribuci\'on es usualmente denotada como $\pi^\star( \, \cdot \, )$ y puede ser interpretada de dos maneras equivalentes, sin importar el estado inicial de la cadena. 
\begin{itemize}
\item \underline{Como probabilidades de encontrar a la cadena en cada estado:}
\[
\forall \text{ estado } i \colon \;
\pi^*(i) \; \define \; \lim_{ t \rightarrow \infty } \;
\Pr ( \, X_t = i \, )
\]
\item \underline{Como fracciones de visitas a estados:} \\[0.5ex] Sup\'ongase que para cada periodo $t$ y cada estado $i$ la variable aleatoria \linebreak $N_t(i)$ es igual al n\'umero de veces, desde el arranque de la cadena hasta el periodo $t$, que la cadena ha visitado el estado $i$. Entonces: 
\[
\forall \text{ estado } i \colon \;
\pi^*(i) \; \define \; \lim_{ t \rightarrow \infty } \frac{N_t(i)}{t}
\]
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

C\'alculo de la Distribuci\'on Estacionaria: 
\begin{enumerate}
\item Descartamos todos los estados transitorios. 
\item Escribimos una ecuaci\'on de balance para cada estado recurrente: 
\[
\forall \, \text{estado } k \colon \, \vec{\pi^*}(k) \; = \; 
\sum_{\text{estados }i} \vec{\pi^*}(i) \, \vec{P}(i,k) 
\]
\item Desechamos arbitrariamente una de las ecuaciones anteriores y la reemplazamos por: 
\[
\sum_{\text{estados } k} \vec{\pi^*}(k) \; = \; 1
\]
\item Resolvemos el sistema de ecuaciones lineales resultante. 
\end{enumerate}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Algunos resultados de existencia y unicidad: 
\begin{itemize}
\item Toda cadena aperi\'odica tiene al menos una distribuci\'on estacionaria, \linebreak pero ninguna cadena peri\'odica puede tener una distribuci\'on estacionaria. 
\item En toda cadena aperi\'odica, todas las distribuciones estacionarias le asignan cero probabilidad a cada uno de los estados transitorios. 
\item Si una cadena es erg\'odica entonces su distribuci\'on estacionaria existe, \linebreak es \'unica, y no depende de la distribuci\'on del estado inicial. 
\item Si una cadena es aperi\'odica pero tiene m\'as de una clase recurrente: 
\begin{itemize}
\item Su distribuci\'on estacionaria existe pero no es \'unica y depende de la distribuci\'on del estado inicial. 
\item Todo estado recurrente que puede ser alcanzado desde el estado inicial tiene probabilidad estacionaria estrictamente positiva. 
\end{itemize}

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Origen de las Ecuaciones de Balance: 
\begin{itemize}
\item Supongamos que el estado inicial de una Cadena de Markov no es conocido \linebreak a priori sino que obedece una distribuci\'on inicial $\vec{\pi_0} \in \Re^n$, donde: 
\[
\forall x \colon \, \vec{\pi_0}(x) \, = \, \Pr( \, X_0 = x \, )
\]
\item Como caso especial, sup\'ongase que el estado inicial es conocido, \eg \linebreak que $X_0 = x_0$. Entonces la distribuci\'on inicial ser\'ia: 
\[
\vec{\pi_0}(x_0) \, = \, 1; \qquad
\forall x \neq x_0 \colon \, \vec{\pi_0}(x) \, = \, 0;
\]
\end{itemize}
\framebreak

\begin{itemize}
\item Ahora, si denotamos a $\vec{\pi_1}$ como la distribuci\'on del primer estado, \linebreak tenemos que para todo posible primer estado $x_1$ :
\begin{align*}
\forall x_1 \colon \, \vec{\pi_1}(x_1) \, 
& = \, \Pr( \, X_1 = x_1 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_0} \Pr( \, X_0 = x_0 \, ) \; \Pr( \, X_1 = x_1 \mid X_0 = x_0 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_0} \vec{\pi_0}(x_0) \, \vec{P}(x_0,x_1)
\end{align*}
Matricialmente, eso equivale a: 
\[
\vec{\pi_1'} \, = \, \vec{\pi_0'} \, \vec{P}
\]
\end{itemize}
\framebreak

\begin{itemize}
\item Luego, si denotamos a $\vec{\pi_2}$ como la distribuci\'on del segundo estado, \linebreak tenemos que para todo posible segundo estado $x_2$ :
\begin{align*}
\forall x_2 \colon \, \vec{\pi_2}(x_2) \,
& = \, \Pr( \, X_2 = x_2 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_1} \Pr( \, X_1 = x_1 \, ) \; \Pr( \, X_2 = x_2 \mid X_1 = x_1 \, ) \\[1ex]
& = \, \sum_{\text{estados } x_1} \vec{\pi_1}(x_1) \, \vec{P}(x_1,x_2)
\end{align*}
Matricialmente, tenemos que: 
\[
\vec{\pi_2'} \, = \, \vec{\pi_1'} \, \vec{P}
\]
\end{itemize}
\framebreak

\begin{itemize}
\item M\'as generalmente, si conocemos la distribuci\'on del estado actual $\vec{\pi_t}$, entonces para la distribuci\'on del siguiente estado, denotada $\vec{\pi_{t+1}}$, \linebreak es el caso que: 
\begin{align*}
\forall x_{t+1} \colon \, \vec{\pi_{t+1}}(x_{t+1}) \, 
& = \, \sum_{\text{estados } x_t} \Pr( \, X_t = x_t \, ) \; \Pr( \, X_{t+1} = x_{t+1} \mid X_t = x_t \, ) \\[1ex]
& = \, \sum_{\text{estados } x_t} \vec{\pi_t}(x_t) \, \vec{P}(x_t,x_{t+1})
\end{align*}
Matricialmente, tenemos que: 
\[
\vec{\pi_{t+1}'} \, = \, \vec{\pi_t'} \, \vec{P}
\]
%\item Y mediante inducci\'on matem\'atica, es f\'acil ver que: 
%\[
%\forall t \geq 1 \colon \;
%\vec{\pi_t'} \, = \, \vec{\pi_0'} \, \vec{P}^t
%\]
\end{itemize}
\framebreak

\begin{itemize}
\item Si la Cadena de Markov es irreducible entonces sin importar la distribuci\'on inicial $\vec{\pi_0}$ es el caso que la distribuci\'on del estado actual $\vec{\pi_t}$ converge a una \'unica distribuci\'on $\vec{\pi^*}$, conocida como la distribuci\'on estacionaria o la distribuci\'on en estado estable. \Iec 
\[
\exists! \, \vec{\pi^*} \in \Pr^n, \; \forall \, \vec{\pi_0} \in \Pr^n \; \colon \;
\lim_{ t \rightarrow \infty } \vec{\pi_t} \; = \;
\vec{\pi^*}
\]
\item Adem\'as, si la distribuci\'on estacionaria existe entonces es invariante: 
\[
\vec{(\pi^*)'} \, = \, \vec{(\pi^*)'} \, \vec{P}
\]
Esto implica que si la distribuci\'on del estado inicial de la cadena es igual a \linebreak la distribuci\'on estacionaria, \ie que si $X_0 \sim \vec{\pi^*}$, entonces la distribuci\'on de todo estado ser\'a igual a la distribuci\'on estacionaria, \ie para todo $t \geq 1$ \linebreak es el caso que $X_t \sim \vec{\pi^*}$. 
\item Finalmente, escribiendo la ecuaci\'on matricial anterior como un sistema de ecuaciones escalares obtenemos: 
\[
\forall \, \text{estado } k \colon \, \vec{\pi^*}(k) \; = \; 
\sum_{\text{estados }i} \vec{\pi^*}(i) \, \vec{P}(i,k) 
\]
N\'otese que las ecuaciones de balance no son linealmente independientes, \linebreak lo que significa que siempre existir\'a una ecuaci\'on redundante. 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\textbf{Ejercicio en Clase:}

Carlos es un aficionado del f\'utbol local quien, convenientemente, apoya a Barcelona o a Emelec dependiendo de cual de los dos equipos haya ganado el \'ultimo partido. Cuando Barcelona gana un partido, la probabilidad de que vuelva a ganar es del 60\%. En cambio, cuando Emelec gana la probabilidad de que vuelva a ganar es del 50\%. 

Modele el comportamiento de Carlos como una Cadena de Markov y encuentre la fracci\'on del tiempo que \'el apoya a cada equipo. 

\framebreak

\textbf{Ejercicio en Clase:}

Una m\'aquina caprichosa tiene el siguiente comportamiento: 
\begin{itemize}
\item Si la m\'aquina termina el d\'ia en buen estado, la misma terminar\'a el siguiente d\'ia en buen estado con probabilidad $p$. Caso contrario terminar\'a averiada. 
\item Si la m\'aquina termina el d\'ia averiada entonces los t\'ecnicos se tomar\'an todo el siguiente d\'ia para intentar arreglarla. Con probabilidad $q$ lograr\'an arreglar la m\'aquina; caso contrario, tendr\'an que volverlo a intentar el siguiente d\'ia. 
\end{itemize}

Con todo esto en mente, construya un modelo de Cadena de Markov del comporamiento de esta m\'aquina y calcule el porcentaje del tiempo que la m\'aquina estar\'a operativa y averiada como funci\'on de $p$ y $q$. 

\framebreak

\textbf{Ejercicio en Clase:}

Usualmente las Cadenas de Markov no son modelos suficientemente complejos como para representar el comportamiento humano, puesto que nuestros cerebros no tienen la Propiedad Markoviana, \ie tenemos memoria. A\'un asi, podemos usar cadenas de Markov para modelar a personas err\'aticas, impredecibles y posiblemente irracionales. Por ejemplo, considere el siguiente modelo de la presidencia de Donald Trump, donde los estados son: 
\begin{enumerate}
\item Hablar de como gan\'o las elecciones obteniendo la mayor\'ia de los colegios electorales, a pesar de haber perdido el voto popular por m\'as de dos millones de votos. 
\item Defenderse del esc\'andalo de Russia. 
\item Insistir en construir una pared en la frontera sur con M\'exico. 
\framebreak
\item Hablar de los acuerdos de comerciales que dice que renegociar\'a (\eg NAFTA) y que dice que ser\'an ventajosos para su pa\'is. 
\item Pelearse con celebridades en Twitter. 
\end{enumerate}
\fullskip

La matriz de transici\'on para este modelo es: 
\[
\vec{P} \; = \; 
\left[
\begin{array}{ccccc}
0.5 & 0 & 0.25 & 0.25 & 0 \\
0 & 0.6 & 0 & 0 & 0.4 \\
0 & 1 & 0 & 0 & 0 \\
0.9 & 0.1 & 0 & 0 & 0 \\
0 & 0.3 & 0.3 & 0 & 0.4
\end{array}
\right]
\]
\halfskip

Con esto en mente, calcule la fracci\'on del tiempo a largo plazo que Donald Trump dedicar\'a a cada una de sus actividades. 

\end{frame}

% =================================================================
\subsection{Recompensas y Probabilidades de Absorci\'on}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejemplo aleatorio:}

Considere el siguiente modelo de una acci\'on en un proyecto: 
\begin{itemize}
\item El proyecto empieza en el estado $A$, en el cual genera utilidades de \$200 mensuales. El proyecto avanza al estado $B$ con probabilidad del 40\% y permanece en el mismo estado con probabilidad del 60\%. 
\item Una vez que el proyecto alcanza el estado $B$ genera \$400 mensuales. En este estado el proyecto avanza al estado $C$ con probabilidad del 30\% y permanece en el mismo estado con probabilidad del 70\%. 
\item En el estado $C$ el proyecto genera \$700 mensuales. El proyecto regresa al estado $B$ con probabilidad del 50\% y permanece en el mismo estado con probabilidad del 50\%. 
\end{itemize}
\framebreak

\begin{figure}[htb]
\centering
\def\svgwidth{0.98\columnwidth}
\input{figures/fig_recompensas-00.eps_tex}
\end{figure}
\framebreak

Considere ahora las siguientes preguntas, suponiendo que el proyecto acaba de empezar y que nosotros somos los due\~nos de una acci\'on en el mismo. 
\begin{itemize}
\item A largo plazo, cu\'anta utilidad genera el proyecto por periodo?
\item Sup\'ongase que la tasa de inter\'es es $r = 5\%$. Cu\'al es el Valor Actual Neto Esperado (VAN-E) de la acci\'on? \Ie cu\'al deber\'ia ser su precio? 
\item Cu\'al es el n\'umero esperado de per\'iodos que transcurrir\'an hasta que el proyecto alcance el estado $B$ por primera vez? Y hasta que el proyecto alcance el estado $C$ por primera vez? 
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

\underline{Ejemplo aleatorio:}

Un inversionista de riesgo se encuentra evaluando varias nuevas empresas, \linebreak por lo cual las ha clasificado de la siguiente manera: 
\begin{itemize}
\item Las empresas rango $A$ son las mejores. Cada trimestre una empresa rango $A$ logra volverse totalmente rentable con probablidad del 20\%, se mantiene en el mismo rango con probabilidad del 50\% y desciende de rango con probabilidad del 30\%. 
\item Las empresas rango $B$ son las segundas mejores. Cada trimestre una empresa rango $B$ asciende a rango $A$ con probabilidad del 25\%, se mantiene en el mismo rango con probabilidad del 55\% y desciende de rango con probabilidad del 20\%. 
\item Las empresas rango $C$ son las problem\'aticas. Cada trimestre una empresa rango $C$ asciende a rango $B$ con probabilidad del 30\%, se mantiene en el mismo rango con probabilidad del 50\% y quiebra con probabilidad del 20\%. 
\end{itemize}
\framebreak

\begin{figure}[htb]
\centering
\def\svgwidth{0.98\columnwidth}
\input{figures/fig_absorcion-00.eps_tex}
\end{figure}
\framebreak

Complete las siguientes actividades: 
\begin{itemize}
\item Para cada rango de empresa, calcule la probabilidad de que una empresa de ese rango eventualmente \textit{(i)} logre volverse totalmente rentable o \textit{(ii)} quiebre. 
\item Suponga que el inversionista compra 200 acciones de empresas rango $A$ a \$3.40 cada una y 300 acciones de empresas rango $B$ a \$1.80 cada una. Suponiendo que el inversionista puede vender las acciones de una empresa que logra ser totalmente rentable en al menos \$5.00 cada una, y que el valor de una acci\'on se pierde totalmente cuando su respectiva empresa quiebra, es este plan de inversi\'on (\ie esta apuesta) rentable?
\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Cadenas de Markov con Recompensas: 
\begin{itemize}
\item Agregamos al modelo una funci\'on de recompensa $R$ que le asigna a cada estado $i$ una recompensa o ganancia $R(i)$. 
\item Si la cadena es aperi\'odica y tiene una sola clase recurrente entonces la recompensa esperada por per\'iodo, denotada $\overline{R}$, se calcula ponderando la funci\'on de recompensa por las probabilidades estacionarias. \Iec
\[
\overline{R} \; = \; \sum_{\text{estados }i} R(i) \, \vec{\pi^*}(i)
\]
\framebreak

\item En algunos modelos financieros se nos provee de una tasa de inter\'es $r \in (0,1)$ y se nos solicita que calculemos el Valor Actual Neto Esperado (VAN-E) de la recompensa total acumulada a lo largo del horizonte infinito del modelo. Para esto primero calculamos el factor de descuento:  
\[
\gamma \; = \; \frac{1}{1 + r}
\]
Luego definimos una funci\'on $V$ que le asigna a cada estado $i$ el VAN-E de la recompensa total que acumular\'ia un agente que empieza el proceso desde el estado $i$, denotado $V(i)$. Finalmente calculamos los valores de la funci\'on escribiendo de manera recursiva una \emph{ecuaci\'on de valor} para cada estado: 
\[
\forall \, \text{estado } i \colon \; V(i) \; = \; R(i) \; + \;
\gamma \, \sum_{\text{estados }j} \vec{P}(i,j) \, V(j)
\]
\framebreak

\item Sup\'ongase ahora que la cadena se encuentra en el estado $i$ y que nos interesa calcular el tiempo esperado de primera visita al estado $k$, \ie el n\'umero esperado de per\'iodos que transcurrir\'an hasta que la cadena visite el estado $k$. 

Entonces podemos definir una funci\'on $T$ que le asigna a cada estado $i$ el tiempo esperado de primera visita al estado $k$, denotado $T(i)$, y calcular los valores de la funci\'on escribiendo de manera recursiva una ecuaci\'on de tiempo esperado de primera visita para cada estado: 
\begin{align*}
& T(k) = 0 \\
& \forall \, \text{estado } i \neq k \colon \; T(i) \; = \; 1 \; + \;
\sum_{\text{estados }j} \vec{P}(i,j) \, T(j)
\end{align*}
\framebreak

\item Como hecho interesante, las ecuaciones de tiempo esperado de primera visita se pueden obtener a partir del m\'etodo para VAN-E en modelos financieros. M\'as precisamente: 
\begin{enumerate}
\item Definimos una funci\'on de recompensa que le asigna una unidad a cada estado excepto al estado $k$ (al cual le asigna cero unidades). 
\item Fijamos la tasa de inter\'es en cero, \ie $r = 0$, lo cual a su vez causa que las recompensas futuras no sean descontadas, \ie $\gamma = 1$. 
\item Renombramos la funci\'on $V$ como funci\'on $T$, fijamos $T(k) = 0$ y escribimos una ecuaci\'on de valor para cada estado. 
\end{enumerate}

\end{itemize}

\end{frame}

% -----------------------------------------------------------------
\begin{frame}[allowframebreaks]
\frametitle{\insertsubsection}

Probabilidades de Absorci\'on: 
\begin{itemize}
\item Sup\'ongase que una cadena tiene al menos un estado transitorio que puede alcanzar a cualquiera de dos estados absorbentes, los cuales denotaremos como $k_1$ y $k_2$, y que nos interesa calcular la probabilidad de que la cadena alcance cada uno de los dos estados absorbentes si empieza desde cada uno de los otros estados. 

Entonces podemos definir una funci\'on $\alpha$ que le asigna a cada estado $i$ la probabilidad de que alcanzar el estado absorbente $k_1$ desde ese estado, denotada $\alpha(i)$, y calcular los valores de la funci\'on escribiendo de manera recursiva una ecuaci\'on de absorci\'on para cada estado: 
\begin{align*}
& \alpha(k_1) = 1 \\
& \alpha(k_2) = 0 \\
& \forall \, \text{estado } i \notin \{ k_1, k_2 \}
\colon \; \alpha(i) \; = \,
\sum_{\text{estados }j} \vec{P}(i,j) \, \alpha(j)
\end{align*}


\end{itemize}

\end{frame}

\end{document}
